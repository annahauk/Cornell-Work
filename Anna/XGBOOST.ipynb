{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> <font color = #03396c> JPMC TEAM #1</b></font>\n",
    "## <b>Price Prediction using XGBOOST</b>\n",
    "In this notebook, we will create dataframes of the S&P500 stocks' price percentage change over a week for the year of 2022. We will then use the clusters we found from our cluster exploration to prove our hypothesis that: 'Using clusters as opposed to all the stocks in the XGBoost model will, in turn, produce more accruate price predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies#S%26P_500_component_stocks')\n",
    "table_symbol = data[0]\n",
    "table_industry = data[0]['GICS Sector']\n",
    "\n",
    "#these 2 lists are in order with one another\n",
    "symbols = list(table_symbol.Symbol.values)\n",
    "industries = list(table_industry.values) ##Industry Sector\n",
    "\n",
    "remove = []\n",
    "\n",
    "symbols_to_remove = ['BF.B', 'BRK.B', 'KVUE', 'VLTO','SPY']\n",
    "\n",
    "for i, symbol in enumerate(symbols):\n",
    "    if symbol in symbols_to_remove:\n",
    "        remove.append(i)\n",
    "\n",
    "for i in remove:\n",
    "    symbols.remove(symbols[i])\n",
    "    industries.remove(industries[i])\n",
    "\n",
    "print(len(symbols))\n",
    "\n",
    "symbol_industry = dict(zip(symbols,industries))\n",
    "print(len(symbol_industry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = yf.Tickers('AAPL')\n",
    "\n",
    "APPLdf = tickers.tickers['AAPL'].history(period=\"5d\", start=\"2022-01-01\", end=\"2022-12-31\")\n",
    "APPLdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['Open', 'Low', 'High','Volume', 'Dividends', 'Stock Splits']\n",
    "APPLdf = APPLdf.drop(columns=drop_cols, axis = 1)\n",
    "APPLdf.index = APPLdf.index.astype(str).str.split(' ').str[0]\n",
    "APPLdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "fig = make_subplots(rows=1, cols=1, subplot_titles=('Price of APPL for 2022',))\n",
    "\n",
    "# Add trace for Close price\n",
    "fig.add_trace(go.Scatter(x=APPLdf.index, y=APPLdf['Close'], name='Close Price'), row=1, col=1)\n",
    "\n",
    "# Get unique months in the DataFrame\n",
    "unique_months = pd.to_datetime(APPLdf.index).to_period('M').unique()\n",
    "\n",
    "# Update x-axis layout to show ticks for each month\n",
    "fig.update_xaxes(\n",
    "    tickmode='array',\n",
    "    tickvals=unique_months.to_timestamp(),  # Convert to timestamp for plotting\n",
    "    ticktext=unique_months.strftime('%b'),  # Displaying abbreviated month names\n",
    ")\n",
    "# Show figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = [\"2022-01-17\",\"2022-02-21\",\"2022-04-15\", \"2022-05-30\", \"2022-06-20\", \"2022-07-4\", \"2022-09-5\", \"2022-11-24\",\"2022-12-26\"]\n",
    "len(holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_df = pd.DataFrame(index=holidays)\n",
    "holiday_df['Date'] = holiday_df.index\n",
    "\n",
    "# Add another column 'Close' with NaN values\n",
    "holiday_df['Close'] = float('nan')\n",
    "\n",
    "# Set the 'Date' column as the index\n",
    "holiday_df.set_index('Date', inplace=True)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "holiday_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLdf.loc[\"2022-11-25\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming APPLdf and holiday_df are DataFrames\n",
    "\n",
    "# Concatenate the original DataFrame with the holiday DataFrame\n",
    "frames = [APPLdf, holiday_df]\n",
    "result_df = pd.concat(frames)\n",
    "\n",
    "# Convert the index to a consistent data type (e.g., Timestamp)\n",
    "result_df.index = pd.to_datetime(result_df.index)\n",
    "\n",
    "# Sort the index to maintain order\n",
    "result_df = result_df.sort_index()\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "APPL1 = result_df\n",
    "APPL1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert index to datetime if it's in string format\n",
    "APPL1.index = pd.to_datetime(APPL1.index)\n",
    "\n",
    "# Create a new DataFrame with the desired structure\n",
    "new_df = pd.DataFrame(index=[f'APPL Week {week}' for week in range(1, 53)],\n",
    "                      columns=['Day 1', 'Day 2', 'Day 3', 'Day 4', 'Day 5'])\n",
    "\n",
    "# Iterate through rows of the original DataFrame and fill the new DataFrame\n",
    "for i, row in APPL1.iterrows():\n",
    "    week = i.week\n",
    "    day = i.dayofweek\n",
    "    \n",
    "    # If there are rows for the current week and day, set the mean close price\n",
    "    if not pd.isna(row['Close']):\n",
    "        new_df.at[f'APPL Week {week}', f'Day {day + 1}'] = row['Close']\n",
    "\n",
    "# Display the new DataFrame\n",
    "APPL = new_df\n",
    "nan_rows = new_df[new_df.isna().any(axis=1)]\n",
    "nan_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert index to datetime if it's in string format\n",
    "APPL1.index = pd.to_datetime(APPL1.index)\n",
    "\n",
    "# Create a new DataFrame with the desired structure\n",
    "new_df = pd.DataFrame(index=[f'APPL Week {week}' for week in range(1, 53)],\n",
    "                      columns=['Day 1', 'Day 2', 'Day 3', 'Day 4', 'Day 5'])\n",
    "\n",
    "# Iterate through rows of the original DataFrame and fill the new DataFrame\n",
    "for i, row in APPL1.iterrows():\n",
    "    week = i.week\n",
    "    day = i.dayofweek\n",
    "    \n",
    "    # If there are rows for the current week and day, set the mean close price\n",
    "    if not pd.isna(row['Close']):\n",
    "        new_df.at[f'APPL Week {week}', f'Day {day + 1}'] = row['Close']\n",
    "\n",
    "# Drop rows with NaN values\n",
    "new_df = new_df.dropna()\n",
    "\n",
    "# Display the new DataFrame\n",
    "APPL = new_df\n",
    "APPL = APPL.drop(['APPL Week 1'], axis=0)\n",
    "APPL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLPCT1 = APPL1.pct_change()\n",
    "APPLPCT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert index to datetime if it's in string format\n",
    "APPLPCT1.index = pd.to_datetime(APPL1.index)\n",
    "\n",
    "# Create a new DataFrame with the desired structure\n",
    "new_df = pd.DataFrame(index=[f'APPL PC Week {week}' for week in range(1, 53)],\n",
    "                      columns=['Day 1', 'Day 2', 'Day 3', 'Day 4', 'Day 5'])\n",
    "\n",
    "# Iterate through rows of the original DataFrame and fill the new DataFrame\n",
    "for i, row in APPLPCT1.iterrows():\n",
    "    week = i.week\n",
    "    day = i.dayofweek\n",
    "    \n",
    "    # If there are rows for the current week and day, set the mean close price\n",
    "    if not pd.isna(row['Close']):\n",
    "        new_df.at[f'APPL PC Week {week}', f'Day {day + 1}'] = row['Close']\n",
    "\n",
    "new_df.replace(0, pd.NA, inplace=True)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "new_df = new_df.dropna()\n",
    "\n",
    "# Display the new DataFrame\n",
    "APPLPCT = new_df\n",
    "APPLPCT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = yf.Tickers('MMM')\n",
    "\n",
    "MMMdf = tickers.tickers['MMM'].history(period=\"5d\", start=\"2022-01-01\", end=\"2022-12-31\")\n",
    "drop_cols = ['Open', 'Low', 'High','Volume', 'Dividends', 'Stock Splits']\n",
    "MMMdf = MMMdf.drop(columns=drop_cols, axis = 1)\n",
    "MMMdf.index = MMMdf.index.astype(str).str.split(' ').str[0]\n",
    "frames = [MMMdf, holiday_df]\n",
    "result_df = pd.concat(frames)\n",
    "\n",
    "# Convert the index to a consistent data type (e.g., Timestamp)\n",
    "#result_df.index = pd.to_datetime(result_df.index)\n",
    "\n",
    "# Sort the index to maintain order\n",
    "result_df = result_df.sort_index()\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "MMM1 = result_df\n",
    "MMM1\n",
    "pct = MMM1.ffill().pct_change()\n",
    "pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct = MMM1.ffill().pct_change()\n",
    "pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of S&P 500 stocks\n",
    "sp500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "sp500_tickers = sp500['Symbol'].tolist()\n",
    "\n",
    "# Remove specified tickers from the list of S&P 500 stock\n",
    "# Function to fetch data and create price percentage DataFrame\n",
    "def get_price_percentage_df(ticker):\n",
    "    try:\n",
    "        stock_data = yf.download(ticker, start=\"2022-01-01\", end=\"2022-12-31\")\n",
    "        drop_cols = ['Open', 'Low', 'High', 'Adj Close', 'Volume']\n",
    "        stock_data = stock_data.drop(columns=drop_cols, axis=1)\n",
    "        stock_data.index = stock_data.index.astype(str).str.split(' ').str[0]\n",
    "        result_df = stock_data.ffill().pct_change()\n",
    "        result_df.columns = [f\"{ticker}\" for col in result_df.columns]\n",
    "        return result_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> Here create the cluster dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fetch data for each ticker and create price percentage DataFrame\n",
    "pct_dfs = []\n",
    "for ticker in sp500_tickers:\n",
    "        pct_df = get_price_percentage_df(ticker)\n",
    "        if not pct_df.empty:\n",
    "            pct_dfs.append(pct_df)\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "sp500_pct_df = pd.concat(pct_dfs, axis=1)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "sp500_pct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv('df_labels.csv')\n",
    "df_labels = df_labels.loc[:496]\n",
    "comp = list(df_labels['Company'])\n",
    "# if the company in sp500pct is not in comp, drop it\n",
    "for i in sp500_pct_df.columns:\n",
    "    if i not in comp:\n",
    "        sp500_pct_df.drop(i, axis=1, inplace=True)\n",
    "sp500_pct_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = [\"2022-01-17\",\"2022-02-21\",\"2022-04-15\", \"2022-05-30\", \"2022-06-20\", \"2022-07-4\", \"2022-09-5\", \"2022-11-24\",\"2022-12-26\"]\n",
    "columns = sp500_pct_df.columns\n",
    "\n",
    "# Create holiday_df| with NaN values for each date and columns matching sp500_pct_df\n",
    "holiday_df = pd.DataFrame(index=holidays, columns=columns)\n",
    "holiday_df['Date'] = holiday_df.index\n",
    "\n",
    "# Set the 'Date' column as the index\n",
    "holiday_df.set_index('Date', inplace=True)\n",
    "holiday_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat([sp500_pct_df, holiday_df], axis=0)\n",
    "# Sort the DataFrame by index to maintain order\n",
    "result_df = result_df.sort_index()\n",
    "sp500_pct_df = result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_pct_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_values = sp500_pct_df.T.iloc[0].values\n",
    "\n",
    "# Create a list of week strings\n",
    "weeks = [f\"MMM Week {i}\" for i in range(1, 53)]\n",
    "\n",
    "# Create an empty DataFrame with the specified index and columns\n",
    "MMMweeks = pd.DataFrame(index=weeks, columns=[\"Day 1\", \"Day 2\", \"Day 3\", \"Day 4\", \"Day 5\"])\n",
    "\n",
    "# Set the values in MMMweeks\n",
    "for i in range(0, len(company_values), 5):\n",
    "    week_number = (i // 5) + 1\n",
    "    week_name = f\"MMM Week {week_number}\"\n",
    "    MMMweeks.loc[week_name] = company_values[i:i + 5]\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "#MMMweeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MMMdf.pct_change().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "\n",
    "# Iterate through each stock\n",
    "for stock in sp500_pct_df.T.index:\n",
    "    # Get the values for the current stock\n",
    "    stock_values = sp500_pct_df.T.loc[stock].values\n",
    "    \n",
    "    # Create a list of week strings\n",
    "    weeks = [f\"{stock} Week {i}\" for i in range(1, 53)]\n",
    "\n",
    "    # Create an empty DataFrame with the specified index and columns\n",
    "    stock_df = pd.DataFrame(index=weeks, columns=[\"Day 1\", \"Day 2\", \"Day 3\", \"Day 4\", \"Day 5\"])\n",
    "\n",
    "    # Set the values in the DataFrame\n",
    "    for i in range(0, len(stock_values), 5):\n",
    "        week_number = (i // 5) + 1\n",
    "        week_name = f\"{stock} Week {week_number}\"\n",
    "        stock_df.loc[week_name] = stock_values[i:i + 5]\n",
    "\n",
    "    # Append the DataFrame for the current stock to the list\n",
    "    dfs.append(stock_df)\n",
    "    #add a column with the stock names\n",
    "    stock_df['Stock'] = stock\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "result_df = pd.concat(dfs)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "result_df = result_df.dropna()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster1 = 391\n",
    "#cluster2 = 27\n",
    "#cluster3 = 79\n",
    "df_labels = pd.read_csv('df_labels.csv')\n",
    "df_labels = df_labels.loc[:496]\n",
    "# \n",
    "# make 3 lists of the 3 different clusters of stocks\n",
    "cluster1 = df_labels[df_labels['Cluster_Label']==1]\n",
    "cluster2 = df_labels[df_labels['Cluster_Label']==2]\n",
    "cluster3 = df_labels[df_labels['Cluster_Label']==3]\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 79/497\n",
    "c = b * 20874\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dataframe subset for clusters 1-3\n",
    "#list of the companies in cluster1\n",
    "cluster1_comp = list(cluster1['Company'])\n",
    "# make a dataframe subset from the result_df of the companies in cluster1_comp\n",
    "cluster1_df = result_df[result_df['Stock'].isin(cluster1_comp)]\n",
    "#repeat for cluster2\n",
    "cluster2_comp = list(cluster2['Company'])\n",
    "cluster2_df = result_df[result_df['Stock'].isin(cluster2_comp)]\n",
    "#repeat for cluster3\n",
    "cluster3_comp = list(cluster3['Company'])\n",
    "cluster3_df = result_df[result_df['Stock'].isin(cluster3_comp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the 'Stock' column from each dataframe\n",
    "cluster1_df.drop(['Stock'], axis=1, inplace=True)\n",
    "cluster2_df.drop(['Stock'], axis=1, inplace=True)\n",
    "cluster3_df.drop(['Stock'], axis=1, inplace=True)\n",
    "result_df.drop(['Stock'], axis=1, inplace=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropweeks = [1,3,8,15,22,25,26,27,36,47,52]\n",
    "len(dropweeks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>There are 41 weeks of trading data per company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_pct_df = result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_pct_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sp500_pct_df = sp500_pct_df.astype('float64')\n",
    "cluster1_df = cluster1_df.astype('float64')\n",
    "cluster2_df = cluster2_df.astype('float64')\n",
    "cluster3_df = cluster3_df.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> XGBOOST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def train_xgboost_regressor(X, y, params=None, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Train an XGBoost regressor on the given dataset.\n",
    "    Returns:\n",
    "    - model: Trained XGBoost regressor\n",
    "    - y_pred: Predictions on the test set\n",
    "    - mse: Mean squared error on the test set\n",
    "    \"\"\"\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, \n",
    "                                                        random_state=random_state)\n",
    "\n",
    "    # Initialize the XGBoost regressor\n",
    "    model = xgb.XGBRegressor() if params is None else xgb.XGBRegressor(**params)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate mean squared error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    return model, y_pred, mse, y_test\n",
    "#X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def xgboost_tuned(X, y, params=None, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Train an XGBoost regressor on the given dataset.\n",
    "    Returns:\n",
    "    - model: Trained XGBoost regressor\n",
    "    - y_pred: Predictions on the test set\n",
    "    - mse: Mean squared error on the test set\n",
    "    \"\"\"\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, \n",
    "                                                        random_state=random_state)\n",
    "\n",
    "    # Define the parameter grid for grid search\n",
    "    param_grid = {\n",
    "        #'gamma': [0.001, 0.005, 0.01, 0.02],\n",
    "        'learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "        'max_depth': [2, 3, 5, 7, 8, 10],\n",
    "        'n_estimators': [100, 200, 300, 400]\n",
    "    }\n",
    "\n",
    "    # Initialize the XGBoost regressor\n",
    "    model = xgb.XGBRegressor() if params is None else xgb.XGBRegressor(**params)\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model and its parameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Make predictions on the test set using the best model\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate mean squared error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    return best_model, y_pred, mse, best_params, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sp500_pct_df['Day 5']\n",
    "X = sp500_pct_df.drop(columns='Day 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = train_xgboost_regressor(X,y)\n",
    "mse_sp500 = sp500[2]\n",
    "mse_sp500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_tuned = xgboost_tuned(X,y)\n",
    "mse_sp500_tuned = sp500_tuned[2]\n",
    "mse_sp500_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = sp500_tuned[3]\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# MSE values\n",
    "mse_values = [mse_sp500, mse_sp500_tuned]\n",
    "\n",
    "# Model names\n",
    "model_names = ['XGBoost', 'Tuned XGBoost']\n",
    "\n",
    "# Creating a bar plot\n",
    "plt.bar(model_names, mse_values, color=['#E5E4E2', '#01477bff'], width=0.8)\n",
    "for i, value in enumerate(mse_values):\n",
    "    plt.text(i, value + 0.000005, f'{value:.10f}', ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('Comparison of MSE between SP500 XGBoost and Tuned XGBoost')\n",
    "\n",
    "# Adjusting the y-axis range\n",
    "plt.ylim(0.00, max(mse_values) + 0.00005)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the predicted price percentage change values with the actual price percentage change values\n",
    "y_pred = sp500[1]\n",
    "y_pred\n",
    "y_test = sp500[3]\n",
    "y_test_tuned = sp500_tuned[4]\n",
    "y_pred_tuned = sp500_tuned[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a table of the predicted values and the actual values\n",
    "comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "comparison_df\n",
    "# combine the 2 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate r2 score\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the MAE and tuned MAE\n",
    "# MAE values\n",
    "mae_values = [mae, mae_tuned]\n",
    "model_names = ['MAE', 'Tuned MAE']\n",
    "plt.title('Comparison of MAE between SP500 XGBoost and Tuned XGBoost')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Mean Absolute Error (MAE)')\n",
    "plt.bar(model_names, mae_values, color=['#E5E4E2', '#01477bff'])\n",
    "for i, value in enumerate(mae_values):\n",
    "    plt.text(i, value + 0.000005, f'{value:.10f}', ha='center', va='bottom')\n",
    "plt.ylim(0.00, 0.025 + 0.0025)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the RMSE and tuned RMSE like the MAE\n",
    "# RMSE values\n",
    "rmse_values = [rmse, rmse_tuned]\n",
    "model_names = ['RMSE', 'Tuned RMSE']\n",
    "plt.title('Comparison of RMSE between SP500 XGBoost and Tuned XGBoost')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Root Mean Squared Error (RMSE)')\n",
    "plt.bar(model_names, rmse_values, color=['#7393B3', '#01477bff'])\n",
    "for i, value in enumerate(rmse_values):\n",
    "    plt.text(i, value + 0.000005, f'{value:.10f}', ha='center', va='bottom')\n",
    "plt.ylim(0.00, 0.025 + 0.0025)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the best parameters \n",
    "best_params = sp500_tuned[3]    \n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Making Dataframes With our Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the list, symbols, to the stocks in the company column of the dataframe\n",
    "# make a list of the ones in symbols that aren't in the column\n",
    "# then remove those from the symbols list\n",
    "remove = []\n",
    "for i, symbol in enumerate(symbols):\n",
    "    if symbol not in list(df_labels['Company']):\n",
    "        remove.append(i)\n",
    "\n",
    "remove\n",
    "# make a list of the stocks that are at the indices in remove\n",
    "remove_symbols = []\n",
    "for i in remove:\n",
    "    remove_symbols.append(symbols[i])\n",
    "remove_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_pct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model on each dataframe\n",
    "y1 = cluster1_df['Day 5']\n",
    "X1 = cluster1_df.drop(columns='Day 5')\n",
    "cluster_1_model = train_xgboost_regressor(X1,y1)\n",
    "cluster_1_mse = cluster_1_model[2]\n",
    "print('Cluster 1 MSE: ' + str(round(cluster_1_mse, 8)))\n",
    "cluster_1_model_tuned = xgboost_tuned(X1,y1)\n",
    "cluster_1_mse_tuned = cluster_1_model_tuned[2]\n",
    "print('Cluster 1 Tuned MSE: ' + str(round(cluster_1_mse_tuned, 8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = cluster2_df['Day 5']\n",
    "X2 = cluster2_df.drop(columns='Day 5')\n",
    "cluster_2_model = train_xgboost_regressor(X2,y2)\n",
    "cluster_2_mse = cluster_2_model[2]\n",
    "print('Cluster 2 MSE: ' + str(round(cluster_2_mse, 8)))\n",
    "cluster_2_model_tuned = xgboost_tuned(X2,y2)\n",
    "cluster_2_mse_tuned = cluster_2_model_tuned[2]\n",
    "print('Cluster 2 Tuned MSE: ' + str(round(cluster_2_mse_tuned, 8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = cluster3_df['Day 5']\n",
    "X3 = cluster3_df.drop(columns='Day 5')\n",
    "cluster_3_model = train_xgboost_regressor(X3,y3)\n",
    "cluster_3_mse = cluster_3_model[2]\n",
    "print('Cluster 3 MSE: ' + str(round(cluster_3_mse, 8)))\n",
    "cluster_3_model_tuned = xgboost_tuned(X3,y3)\n",
    "cluster_3_msetuned = cluster_3_model_tuned[2]\n",
    "print('Cluster 3 Tuned MSE: ' + str(round(cluster_3_msetuned, 8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = cluster_1_model_tuned[3]\n",
    "params2 = cluster_2_model_tuned[3]\n",
    "params3 = cluster_3_model_tuned[3]\n",
    "print(params1)\n",
    "print(params2)\n",
    "print(params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the MSE value for each cluster and their corresponding tuned mse value next to it\n",
    "# MSE values\n",
    "mse_values = [cluster_1_mse, cluster_1_mse_tuned, cluster_2_mse, cluster_2_mse_tuned, cluster_3_mse, cluster_3_msetuned]\n",
    "model_names = ['Cluster 1 MSE', 'Cluster 1 Tuned MSE', 'Cluster 2 MSE', 'Cluster 2 Tuned MSE', 'Cluster 3 MSE', 'Cluster 3 Tuned MSE']\n",
    "plt.title('Comparison of MSE between the 3 Clusters')\n",
    "plt.xlabel('Cluster Models')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "#make the color a gradient of blues\n",
    "plt.bar(model_names, mse_values, color= ['#7393B3', '#01477bff', '#7393B3', '#01477bff', '#7393B3', '#01477bff'], width=0.7)\n",
    "for i, value in enumerate(mse_values):\n",
    "    plt.text(i, value + 0.000005, f'{value:.10f}', ha='center', va='bottom')\n",
    "plt.ylim(0.00, max(mse_values) + 0.00005)\n",
    "plt.xticks(rotation=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the MSE value for each cluster and their corresponding tuned mse value next to it\n",
    "# MSE values\n",
    "mse_values = [cluster_1_mse, cluster_2_mse, cluster_3_mse]\n",
    "model_names = ['Cluster 1 MSE',  'Cluster 2 MSE', 'Cluster 3 MSE']\n",
    "plt.title('MSE between the 3 Clusters')\n",
    "plt.xlabel('Cluster Models')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "#make the color a gradient of blues\n",
    "plt.bar(model_names, mse_values, color= ['#7393B3','#7393B3','#7393B3'], width=0.7)\n",
    "for i, value in enumerate(mse_values):\n",
    "    plt.text(i, value + 0.000005, f'{value:.10f}', ha='center', va='bottom')\n",
    "plt.ylim(0.00, 0.0007 + 0.00005)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the MSE value for each cluster tuned mse value next to it\n",
    "# MSE values\n",
    "mse_values = [cluster_1_mse_tuned,cluster_2_mse_tuned, cluster_3_msetuned]\n",
    "model_names = ['Cluster 1 Tuned MSE', 'Cluster 2 Tuned MSE', 'Cluster 3 Tuned MSE']\n",
    "plt.title('MSE between the 3 Clusters, Tuned')\n",
    "plt.xlabel('Cluster Models')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "#make the color a gradient of blues\n",
    "plt.bar(model_names, mse_values, color= ['#01477bff','#01477bff','#01477bff'], width=0.7)\n",
    "for i, value in enumerate(mse_values):\n",
    "    plt.text(i, value + 0.000005, f'{value:.10f}', ha='center', va='bottom')\n",
    "plt.ylim(0.00, 0.0007 + 0.00005)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mse values for each cluster compared to the original sp500 model mse\n",
    "# MSE values\n",
    "mse_values = [mse_sp500, cluster_1_mse, cluster_2_mse, cluster_3_mse]\n",
    "# plot the mse values for each cluster compared to the original sp500 model mse\n",
    "\n",
    "# Model names\n",
    "model_names = ['XGBoost', 'Cluster 1', 'Cluster 2', 'Cluster 3']\n",
    "\n",
    "# Creating a bar plot\n",
    "plt.bar(model_names, mse_values, color=['#99CCFF', '#6A5ACD', '#9370DB', '#DCD0FF',])\n",
    "for i, value in enumerate(mse_values):\n",
    "    plt.text(i, value + 0.000005, f'{value:.10f}', ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Models: Original XGBoost and Clustered XGBoost')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('Comparison of MSE between XGBoost and Clustered XGBoost')\n",
    "\n",
    "# Adjusting the y-axis range\n",
    "plt.ylim(0.00, max(mse_values) + 0.00005)\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mse values for each cluster compared to the original sp500 model mse\n",
    "# MSE values\n",
    "mse_values = [mse_sp500,mse_sp500_tuned, cluster_1_mse, cluster_2_mse, cluster_3_mse]\n",
    "# plot the mse values for each cluster compared to the original sp500 model mse\n",
    "\n",
    "# Model names\n",
    "model_names = ['XGBoost','XGBoost Tuned', 'Cluster 1', 'Cluster 2', 'Cluster 3']\n",
    "\n",
    "# Creating a bar plot\n",
    "plt.bar(model_names, mse_values, color=['blue', 'purple', 'orange', 'green', 'red',], width=0.6)\n",
    "for i, value in enumerate(mse_values):\n",
    "    plt.text(i, value + 0.000005, f'{value:.10f}', ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Models: Original XGBoost and Clustered XGBoost')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('Comparison of Mean Squared Errors between XGBoost, XGBoost Tuned, and Clustered XGBoost')\n",
    "\n",
    "# Adjusting the y-axis range\n",
    "plt.ylim(0.00, max(mse_values) + 0.00005)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the mse values for each cluster next to the mse tuned values for each cluster\n",
    "mse_values = [cluster_1_mse, cluster_1_mse_tuned, cluster_2_mse, cluster_2_mse_tuned, cluster_3_mse, cluster_3_msetuned]\n",
    "model_names= ['Cluster 1', 'Cluster 1 Tuned', 'Cluster 2', 'Cluster 2 Tuned', 'Cluster 3', 'Cluster 3 Tuned']\n",
    "\n",
    "plt.bar(model_names, mse_values, color=['blue', 'lightblue', 'green', 'lightgreen', 'orange', 'coral'])\n",
    "for i, value in enumerate(mse_values):\n",
    "    plt.text(i, value + 0.000005, f'{value:.10f}', ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('MSE values vs tuned values per cluster')\n",
    "\n",
    "# Adjusting the y-axis range\n",
    "plt.ylim(0.00, max(mse_values) + 0.00005)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot all the tuned model mse values\n",
    "# MSE values\n",
    "mse_values = [mse_sp500_tuned, cluster_1_mse_tuned, cluster_2_mse_tuned, cluster_3_msetuned]\n",
    "model_names = ['XGBoost Tuned', 'Cluster 1 Tuned', 'Cluster 2 Tuned', 'Cluster 3 Tuned']\n",
    "\n",
    "plt.bar(model_names, mse_values, color=['purple', '#4169E1', '#008080', '#89CFF0',])\n",
    "for i, value in enumerate(mse_values):\n",
    "    plt.text(i, value + 0.000005, f'{value:.10f}', ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('MSE Values for All Tuned Models')\n",
    "\n",
    "# Adjusting the y-axis range\n",
    "plt.ylim(0.00, max(mse_values) + 0.00005)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average the mse values for each cluster\n",
    "cluster_average = (cluster_1_mse + cluster_2_mse + cluster_3_mse)/3\n",
    "print('Average MSE for Clustered XGBoost: ' + str(round(cluster_average, 8)))\n",
    "cluster_average_tuned = (cluster_1_mse_tuned + cluster_2_mse_tuned + cluster_3_msetuned)/3\n",
    "print('Average Tuned MSE for Clustered XGBoost: ' + str(round(cluster_average_tuned, 8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot all the tuned model mse values\n",
    "# MSE values\n",
    "mse_values = [mse_sp500, mse_sp500_tuned,cluster_average, cluster_average_tuned]\n",
    "model_names = ['XGBoost', 'XGBoost Tuned','Clustered XGBoost', 'Clustered XGBoost Tuned']\n",
    "plt.bar(model_names, mse_values, color=['#7393B3', '#01477bff', '#7393B3','#01477bff',])\n",
    "for i, value in enumerate(mse_values):\n",
    "    plt.text(i, value + 0.000005, f'{value:.10f}', ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('MSE for XGBoost and Average Clustered XGBoost: Nontuned/Tuned')\n",
    "\n",
    "# Adjusting the y-axis range\n",
    "plt.ylim(0.00, max(mse_values) + 0.00005)\n",
    "#rotate the x axis\n",
    "plt.xticks(rotation=10)\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe of how many companies are in each cluster\n",
    "cluster_counts = pd.DataFrame(df_labels['Cluster_Label'].value_counts())\n",
    "#keep it in 1,2,3 order\n",
    "cluster_counts = cluster_counts.sort_index()\n",
    "#cluster_counts = cluster_counts.T\n",
    "#make the column say \"company count\"\n",
    "cluster_counts.columns = ['Company Count']\n",
    "cluster_counts.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot all the tuned model mse values\n",
    "# MSE values\n",
    "mse_values = [mse_sp500, cluster_average, cluster_average_tuned]\n",
    "model_names = ['XGBoost', 'Cluster-XGBoost', 'Tuned Cluster-XGBoost']\n",
    "plt.bar(model_names, mse_values, color=['purple', '#4169E1', '#C8B4E9'])\n",
    "for i, value in enumerate(mse_values):\n",
    "    plt.text(i, value + 0.000005, f'{value:.10f}', ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('MSE for XGBoost and Average Clustered XGBoost: Nontuned/Tuned')\n",
    "\n",
    "# Adjusting the y-axis range\n",
    "plt.ylim(0.00, max(mse_values) + 0.00005)\n",
    "#rotate the x axis\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot all the tuned model mse values\n",
    "# MSE values\n",
    "mse_values = [mse_sp500, cluster_average]\n",
    "model_names = ['XGBoost', 'Cluster-XGBoost']\n",
    "plt.bar(model_names, mse_values, color=['#E5E4E2', '#01477bff',])\n",
    "for i, value in enumerate(mse_values):\n",
    "    plt.text(i, value + 0.000005, f'{value:.10f}', ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('MSE for XGBoost and Average Cluster-XGBoost')\n",
    "\n",
    "# Adjusting the y-axis range\n",
    "plt.ylim(0.00, max(mse_values) + 0.00005)\n",
    "#rotate the x axis\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE values: Moving Average Percentage Error\n",
    "# Calculate the MAPE for each model\n",
    "mape_values = [mape, mape_tuned, cluster_1_mape, cluster_1_mape_tuned, cluster_2_mape, cluster_2_mape_tuned, cluster_3_mape, cluster_3_mape_tuned]\n",
    "model_names = ['XGBoost', 'XGBoost Tuned', 'Cluster 1', 'Cluster 1 Tuned', 'Cluster 2', 'Cluster 2 Tuned', 'Cluster 3', 'Cluster 3 Tuned']\n",
    "\n",
    "# Create a bar plot\n",
    "plt.bar(model_names, mape_values, color=['#E5E4E2', '#01477bff', '#E5E4E2', '#01477bff', '#E5E4E2', '#01477bff', '#E5E4E2', '#01477bff'])\n",
    "for i, value in enumerate(mape_values):\n",
    "    plt.text(i, value + 0.000005, f'{value:.10f}', ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Mean Absolute Percentage Error (MAPE)')\n",
    "plt.title('Comparison of MAPE between XGBoost and Clustered XGBoost')\n",
    "\n",
    "# Adjust the y-axis range\n",
    "plt.ylim(0.00, max(mape_values) + 0.00005)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
